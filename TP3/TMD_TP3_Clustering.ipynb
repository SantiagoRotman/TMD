{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7LEdjyLSe0X"
      },
      "source": [
        "# Código TP3: Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ndRKaQeASe0a"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.optimize import linear_sum_assignment\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.scale.html\n",
        "from sklearn.preprocessing import scale\n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html\n",
        "from sklearn.decomposition import PCA"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xNe7HEXPSe0d"
      },
      "source": [
        "## Carga de Datasets \"Crabs\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGBZG_SwSe0e",
        "outputId": "6059b7a6-9df8-4a2f-fd70-9f7280f93b0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    sp sex    FL    RW    CL    CW    BD\n",
            "0    B   M   8.1   6.7  16.1  19.0   7.0\n",
            "1    B   M   8.8   7.7  18.1  20.8   7.4\n",
            "2    B   M   9.2   7.8  19.0  22.4   7.7\n",
            "3    B   M   9.6   7.9  20.1  23.1   8.2\n",
            "4    B   M   9.8   8.0  20.3  23.0   8.2\n",
            "..  ..  ..   ...   ...   ...   ...   ...\n",
            "195  O   F  21.4  18.0  41.2  46.2  18.7\n",
            "196  O   F  21.7  17.1  41.7  47.2  19.6\n",
            "197  O   F  21.9  17.2  42.6  47.4  19.5\n",
            "198  O   F  22.5  17.2  43.0  48.7  19.8\n",
            "199  O   F  23.1  20.2  46.2  52.5  21.1\n",
            "\n",
            "[200 rows x 7 columns]\n",
            "[['B' 'M' 8.1 ... 16.1 19.0 7.0]\n",
            " ['B' 'M' 8.8 ... 18.1 20.8 7.4]\n",
            " ['B' 'M' 9.2 ... 19.0 22.4 7.7]\n",
            " ...\n",
            " ['O' 'F' 21.9 ... 42.6 47.4 19.5]\n",
            " ['O' 'F' 22.5 ... 43.0 48.7 19.8]\n",
            " ['O' 'F' 23.1 ... 46.2 52.5 21.1]]\n"
          ]
        }
      ],
      "source": [
        "crabs = pd.read_csv(\"Crabs.csv\", sep=',')\n",
        "crabs = crabs.drop(columns=[\"rownames\", \"index\"])\n",
        "print(crabs)\n",
        "\n",
        "crabs_numpy = crabs.to_numpy()\n",
        "print(crabs_numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9hUfcjRSe0g"
      },
      "source": [
        "## Carga de Datasets \"Lampone\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxFlyBS0Se0h",
        "outputId": "934b6c68-142d-4389-a069-083b6e6ba25b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    anno     m33   m34   m35   m36  m40   m41   m42    m43   m44  ...  m183  \\\n",
            "0   2006   32.24  0.27  0.06  0.01  0.0  0.30  0.02   2.05  0.11  ...  0.00   \n",
            "1   2006   33.41  0.34  0.05  0.01  0.0  0.12  0.02  10.42  0.25  ...  0.00   \n",
            "2   2006   31.93  0.32  0.05  0.01  0.0  0.09  0.02   9.32  0.24  ...  0.00   \n",
            "3   2006   43.62  0.45  0.08  0.02  0.0  0.11  0.02  12.67  0.31  ...  0.00   \n",
            "4   2006   47.08  0.47  0.09  0.02  0.0  0.20  0.03   3.19  0.12  ...  0.00   \n",
            "5   2006   21.38  0.20  0.03  0.00  0.0  0.06  0.01  12.01  0.27  ...  0.00   \n",
            "6   2006   37.20  0.38  0.06  0.01  0.0  0.07  0.02   3.45  0.14  ...  0.00   \n",
            "7   2006   57.00  0.51  0.08  0.00  0.0  0.08  0.02   2.63  0.09  ...  0.00   \n",
            "8   2006   13.31  0.16  0.02  0.00  0.0  0.14  0.02  11.92  0.26  ...  0.00   \n",
            "9   2006  122.75  1.05  0.17  0.01  0.0  0.11  0.02   8.67  0.24  ...  0.00   \n",
            "10  2006   37.70  0.37  0.05  0.00  0.0  0.09  0.02  19.00  0.39  ...  0.00   \n",
            "11  2006   39.47  0.38  0.06  0.01  0.0  0.15  0.02   1.49  0.10  ...  0.00   \n",
            "12  2006   71.67  0.72  0.11  0.01  0.0  0.10  0.03   6.39  0.20  ...  0.00   \n",
            "13  2006   63.11  0.55  0.08  0.01  0.0  0.14  0.02   4.34  0.13  ...  0.00   \n",
            "14  2006   93.73  0.86  0.17  0.01  0.0  0.19  0.02   2.94  0.11  ...  0.00   \n",
            "15  2006  255.31  2.20  0.36  0.02  0.0  0.16  0.02   2.37  0.10  ...  0.00   \n",
            "16  2006   46.34  0.42  0.08  0.01  0.0  0.14  0.02   4.52  0.14  ...  0.00   \n",
            "17  2006   39.09  0.36  0.06  0.01  0.0  0.14  0.02   2.97  0.11  ...  0.00   \n",
            "18  2006   67.26  0.63  0.10  0.01  0.0  0.10  0.01   4.87  0.14  ...  0.00   \n",
            "19  2007   42.50  0.49  0.08  0.01  0.0  0.67  0.05  29.10  0.74  ...  0.00   \n",
            "20  2007   36.19  0.44  0.09  0.01  0.0  0.27  0.04  31.04  0.76  ...  0.00   \n",
            "21  2007   53.86  0.65  0.12  0.01  0.0  0.75  0.07  17.44  0.51  ...  0.00   \n",
            "22  2007   63.97  0.75  0.13  0.01  0.0  0.42  0.06  27.66  0.74  ...  0.00   \n",
            "23  2007  244.96  2.95  0.54  0.02  0.0  0.42  0.05  10.39  0.37  ...  0.00   \n",
            "24  2007   33.00  0.39  0.06  0.01  0.0  0.60  0.05  37.52  0.88  ...  0.00   \n",
            "25  2007   36.43  0.46  0.06  0.01  0.0  0.59  0.05  27.21  0.76  ...  0.00   \n",
            "26  2007   41.35  0.53  0.10  0.02  0.0  0.78  0.07  16.30  0.49  ...  0.00   \n",
            "27  2007   23.65  0.28  0.05  0.00  0.0  0.31  0.04  20.04  0.57  ...  0.00   \n",
            "28  2007   89.40  1.09  0.20  0.01  0.0  0.42  0.05  27.40  0.68  ...  0.00   \n",
            "29  2007   29.75  0.37  0.06  0.02  0.0  0.47  0.05  58.01  1.38  ...  0.00   \n",
            "30  2007   42.33  0.47  0.07  0.01  0.0  0.58  0.05  22.01  0.65  ...  0.00   \n",
            "31  2007   22.83  0.28  0.06  0.01  0.0  0.37  0.05  68.06  1.63  ...  0.00   \n",
            "32  2007  115.23  1.44  0.26  0.02  0.0  0.24  0.03   4.80  0.25  ...  0.00   \n",
            "33  2007   77.09  0.93  0.17  0.01  0.0  0.33  0.05  25.14  0.62  ...  0.00   \n",
            "34  2007  108.28  1.31  0.24  0.02  0.0  0.25  0.04   5.49  0.27  ...  0.00   \n",
            "35  2007   80.24  0.89  0.15  0.01  0.0  0.29  0.04  11.22  0.35  ...  0.00   \n",
            "36  2007   72.15  0.92  0.16  0.02  0.0  0.20  0.04  23.30  0.64  ...  0.00   \n",
            "37  2007   72.43  0.85  0.15  0.01  0.0  0.30  0.04   9.01  0.29  ...  0.00   \n",
            "38  2007   64.49  0.77  0.11  0.01  0.0  0.23  0.04  21.70  0.57  ...  0.00   \n",
            "39  2007   74.17  0.87  0.15  0.01  0.0  0.25  0.03   8.39  0.29  ...  0.00   \n",
            "40  2007   73.78  0.93  0.15  0.01  0.0  0.27  0.03  12.22  0.41  ...  0.00   \n",
            "41  2007  106.97  1.30  0.20  0.01  0.0  0.39  0.04   8.11  0.31  ...  0.00   \n",
            "42  2007   86.67  1.11  0.20  0.02  0.0  0.17  0.03  25.43  0.70  ...  0.00   \n",
            "43  2007  104.89  1.26  0.20  0.01  0.0  0.39  0.04   8.76  0.33  ...  0.00   \n",
            "44  2007   80.30  1.01  0.14  0.01  0.0  0.33  0.03  12.61  0.35  ...  0.00   \n",
            "45  2007   68.23  0.86  0.15  0.02  0.0  0.17  0.03  24.69  0.68  ...  0.01   \n",
            "46  2007  130.02  1.65  0.30  0.02  0.0  0.34  0.04   5.45  0.26  ...  0.00   \n",
            "47  2007   96.95  1.11  0.20  0.01  0.0  0.25  0.04   8.51  0.28  ...  0.00   \n",
            "48  2007   78.34  0.98  0.16  0.01  0.0  0.27  0.04   7.07  0.26  ...  0.00   \n",
            "\n",
            "    m185  m187  m191  m193  m194  m195  m205  N_tipo  Numero  \n",
            "0   0.00  0.00  0.00  0.01  0.00  0.00   0.0       2      2e  \n",
            "1   0.00  0.00  0.00  0.02  0.00  0.00   0.0       2      2d  \n",
            "2   0.00  0.00  0.00  0.01  0.00  0.00   0.0       2      2c  \n",
            "3   0.00  0.00  0.00  0.02  0.00  0.00   0.0       2      2a  \n",
            "4   0.00  0.00  0.00  0.02  0.00  0.00   0.0       2      2b  \n",
            "5   0.00  0.00  0.00  0.01  0.00  0.00   0.0       2      2i  \n",
            "6   0.00  0.00  0.00  0.02  0.00  0.00   0.0       2      2h  \n",
            "7   0.00  0.00  0.00  0.01  0.00  0.00   0.0       2      2g  \n",
            "8   0.00  0.00  0.00  0.01  0.00  0.00   0.0       2      2f  \n",
            "9   0.00  0.00  0.00  0.03  0.00  0.00   0.0      10     10d  \n",
            "10  0.00  0.00  0.00  0.02  0.00  0.00   0.0      10     10h  \n",
            "11  0.00  0.00  0.00  0.01  0.00  0.00   0.0      10     10e  \n",
            "12  0.00  0.00  0.00  0.03  0.00  0.00   0.0      10     10a  \n",
            "13  0.00  0.00  0.00  0.01  0.00  0.00   0.0      10     10i  \n",
            "14  0.00  0.00  0.00  0.03  0.00  0.00   0.0      10     10c  \n",
            "15  0.00  0.00  0.00  0.01  0.00  0.00   0.0      10     10b  \n",
            "16  0.00  0.00  0.00  0.02  0.00  0.00   0.0      10     10g  \n",
            "17  0.00  0.00  0.00  0.01  0.00  0.00   0.0      10     10f  \n",
            "18  0.00  0.00  0.00  0.01  0.00  0.00   0.0      10     10j  \n",
            "19  0.00  0.00  0.00  0.07  0.01  0.00   0.0       2      2m  \n",
            "20  0.00  0.00  0.00  0.07  0.01  0.01   0.0       2      2e  \n",
            "21  0.00  0.00  0.00  0.04  0.00  0.00   0.0       2      2d  \n",
            "22  0.00  0.00  0.00  0.06  0.01  0.00   0.0       2      2k  \n",
            "23  0.00  0.00  0.00  0.05  0.01  0.00   0.0       2      2l  \n",
            "24  0.00  0.00  0.00  0.08  0.01  0.01   0.0       2      2j  \n",
            "25  0.00  0.00  0.00  0.05  0.01  0.00   0.0       2      2i  \n",
            "26  0.00  0.00  0.00  0.02  0.00  0.00   0.0       2      2h  \n",
            "27  0.00  0.00  0.00  0.05  0.00  0.00   0.0       2      2a  \n",
            "28  0.00  0.00  0.00  0.04  0.01  0.00   0.0       2      2c  \n",
            "29  0.00  0.00  0.00  0.03  0.00  0.00   0.0       2      2f  \n",
            "30  0.00  0.00  0.00  0.03  0.01  0.00   0.0       2      2g  \n",
            "31  0.00  0.00  0.00  0.03  0.00  0.00   0.0       2      2b  \n",
            "32  0.01  0.00  0.01  0.18  0.02  0.01   0.0      10     10p  \n",
            "33  0.00  0.00  0.00  0.05  0.00  0.00   0.0      10     10g  \n",
            "34  0.00  0.00  0.00  0.08  0.01  0.00   0.0      10     10j  \n",
            "35  0.00  0.00  0.00  0.08  0.01  0.00   0.0      10     10h  \n",
            "36  0.01  0.01  0.00  0.14  0.02  0.01   0.0      10     10i  \n",
            "37  0.00  0.00  0.00  0.02  0.00  0.00   0.0      10     10a  \n",
            "38  0.00  0.00  0.00  0.04  0.01  0.00   0.0      10     10e  \n",
            "39  0.00  0.00  0.00  0.08  0.01  0.00   0.0      10     10f  \n",
            "40  0.00  0.00  0.00  0.15  0.03  0.01   0.0      10     10o  \n",
            "41  0.00  0.00  0.00  0.08  0.01  0.00   0.0      10     10l  \n",
            "42  0.00  0.00  0.00  0.12  0.02  0.00   0.0      10     10m  \n",
            "43  0.00  0.00  0.00  0.05  0.01  0.00   0.0      10     10k  \n",
            "44  0.00  0.00  0.00  0.13  0.02  0.01   0.0      10     10d  \n",
            "45  0.00  0.00  0.00  0.14  0.02  0.01   0.0      10     10q  \n",
            "46  0.00  0.00  0.00  0.16  0.02  0.01   0.0      10     10n  \n",
            "47  0.00  0.00  0.00  0.06  0.00  0.00   0.0      10     10b  \n",
            "48  0.00  0.00  0.00  0.03  0.00  0.00   0.0      10     10c  \n",
            "\n",
            "[49 rows x 144 columns]\n",
            "[[2006 32.24 0.27 ... 0.0 2 '2e']\n",
            " [2006 33.41 0.34 ... 0.0 2 '2d']\n",
            " [2006 31.93 0.32 ... 0.0 2 '2c']\n",
            " ...\n",
            " [2007 130.02 1.65 ... 0.0 10 '10n']\n",
            " [2007 96.95 1.11 ... 0.0 10 '10b']\n",
            " [2007 78.34 0.98 ... 0.0 10 '10c']]\n"
          ]
        }
      ],
      "source": [
        "lampone = pd.read_csv(\"Lampone.csv\", sep=',')\n",
        "print(lampone)\n",
        "\n",
        "lampone_numpy = lampone.to_numpy()\n",
        "print(lampone_numpy)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elOJW_iwSe0j"
      },
      "source": [
        "## Métodos de Comparación de Resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Jx8i_anmSe0k"
      },
      "outputs": [],
      "source": [
        "# Comentario: para comparar dos soluciones de clustering o una de ellas\n",
        "#  contra las clases originales se suele usar una tabla, como por ejemplo:\n",
        "\n",
        "def comparar_tabla(clusters1, clusters2):\n",
        "\n",
        "    # Suponemos a los clusters numerados desde 0\n",
        "    nclusters1 = np.max(clusters1) + 1\n",
        "    nclusters2 = np.max(clusters2) + 1\n",
        "\n",
        "    conf_matrix = np.zeros((nclusters1, nclusters2), dtype=int)\n",
        "\n",
        "    for i in range(len(clusters1)):\n",
        "        conf_matrix[clusters1[i], clusters2[i]] += 1\n",
        "\n",
        "    print(conf_matrix)\n",
        "    return conf_matrix\n",
        "\n",
        "\n",
        "# pero se puede optimizar el match entre los dos clusterings, para hacer\n",
        "# mejor la tabla, usando:\n",
        "\n",
        "def comparar_tabla_optim(clusters1, clusters2):\n",
        "\n",
        "    # Suponemos a los clusters numerados desde 0\n",
        "    nclusters1 = np.max(clusters1) + 1\n",
        "    nclusters2 = np.max(clusters2) + 1\n",
        "\n",
        "    conf_matrix = np.zeros((nclusters1, nclusters2), dtype=int)\n",
        "\n",
        "    for i in range(len(clusters1)):\n",
        "        conf_matrix[clusters1[i], clusters2[i]] += 1\n",
        "\n",
        "    # minimum weight matching, optimize the matching between a cluster\n",
        "    # in clusters1 with one or more clusters in clusters2\n",
        "    _, col_ind = linear_sum_assignment(-conf_matrix)\n",
        "    optimized_conf_matrix = conf_matrix[:, col_ind]\n",
        "\n",
        "    print(optimized_conf_matrix)\n",
        "    return optimized_conf_matrix\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQuTeAnDSe0m"
      },
      "source": [
        "## Score de Estabilidad de Soluciones de Clustering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-TGKLpOSe0n",
        "outputId": "1e63c515-90b4-4a0a-de99-b2511632a1e8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1.2202479338842975\n"
          ]
        }
      ],
      "source": [
        "# Código de ejemplo de como calcular el score de estabilidad de dos soluciones\n",
        "# de clustering usando Iris\n",
        "\n",
        "data = load_iris()\n",
        "X = data.data\n",
        "n = X.shape[0]\n",
        "\n",
        "# Fijar el número de clusters\n",
        "k = 3\n",
        "\n",
        "# Crear dos muestras aleatorias del 90% de los datos\n",
        "ind1 = np.random.choice(n, int(0.9 * n), replace=False)\n",
        "ind2 = np.random.choice(n, int(0.9 * n), replace=False)\n",
        "\n",
        "# Aplicar K-Means a ambas muestras\n",
        "cc1 = KMeans(n_clusters=k, n_init=10, random_state=0).fit(X[ind1]).labels_\n",
        "cc2 = KMeans(n_clusters=k, n_init=10, random_state=0).fit(X[ind2]).labels_\n",
        "\n",
        "# Reinsertar los clusters en un vector de longitud n, con 0 en los puntos\n",
        "# no seleccionados\n",
        "v1 = np.zeros(n, dtype=int)\n",
        "v2 = np.zeros(n, dtype=int)\n",
        "\n",
        "# Se suman 5 a las etiquetas para permitir el truco de la raíz cuadrada\n",
        "v1[ind1] = cc1 + 5\n",
        "v2[ind2] = cc2 + 5\n",
        "\n",
        "# Crear la matriz de similitud: 1 si están en el mismo cluster,\n",
        "# -1 si están en distinto, 0 si alguno falta\n",
        "def compute_similarity_matrix(v):\n",
        "    a = np.sqrt(np.outer(v, v))\n",
        "    m = np.divide(a, -a, out=np.zeros_like(a), where=a != 0) + 2 * (a == np.round(a))\n",
        "    return m\n",
        "\n",
        "m1 = compute_similarity_matrix(v1)\n",
        "m2 = compute_similarity_matrix(v2)\n",
        "\n",
        "# Calcular el score de estabilidad\n",
        "validos = np.sum((v1 * v2) > 0)\n",
        "if validos > 1:\n",
        "    score = np.sum((m1 * m2)[np.triu_indices(n, k=1)] > 0) / (validos * (validos - 1) / 2)\n",
        "else:\n",
        "    score = 0  # Evita división por cero\n",
        "\n",
        "print(score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Ejercicio 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(200, 5)\n",
            "(200, 2)\n"
          ]
        }
      ],
      "source": [
        "X = crabs.drop(columns=[\"sp\", \"sex\"])\n",
        "y = crabs[[\"sp\", \"sex\"]]\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "xNe7HEXPSe0d",
        "o9hUfcjRSe0g",
        "elOJW_iwSe0j",
        "UQuTeAnDSe0m"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
